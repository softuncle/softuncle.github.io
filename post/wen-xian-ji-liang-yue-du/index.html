<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>文献计量阅读 | Gridea</title>
<link rel="shortcut icon" href="https://softuncle.github.io/favicon.ico?v=1604999503511">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://softuncle.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="文献计量阅读 | Gridea - Atom Feed" href="https://softuncle.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="Science发了一个短文：
Brainard, J. (2020). Scientists are drowning in COVID-19 papers. Can new tools keep them afloat? Science...." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://softuncle.github.io">
  <img class="avatar" src="https://softuncle.github.io/images/avatar.png?v=1604999503511" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              文献计量阅读
            </h2>
            <div class="post-info">
              <span>
                2020-11-10
              </span>
              <span>
                9 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p>Science发了一个短文：<br>
Brainard, J. (2020). Scientists are drowning in COVID-19 papers. Can new tools keep them afloat? Science. https://doi.org/10.1126/science.abc7839<br>
我大概讲一下意思。就是说每天都有大量关于新冠病毒的论文产生，一个人想要阅读所有这些论文是完全不可能的。哪怕是仅仅局限在自己的专业领域，要阅读完所有发表的相关论文，也是不可能完成的任务。那么到底应该怎么做呢？<br>
通常的做法就是删减，找出关键信息。但是因为信息太多，阅读来自科学协会和一些领先期刊的简报以及靠值得信赖的同事口口相传，光靠这些久经考验的有效方式传递的信息就已经使人应接不暇了。<br>
所以靠专业人员筛选，没准是个路子。例如Johns Hopkins University’s (JHU’s) Bloomberg School of Public Health的Kate Grabowski团队正在创建一组有用的COVID-19论文，着重于质量而不是数量。共有40位科学家梳理了文献并从80多篇论文中选出了八个主题，包括疫苗和药物干预措施等，并编写了简短的摘要。该团队已经排除了评论，协议，劣质的建模研究或没有原始发现的文章。<br>
但这样做的问题是耗时耗力，所以科学家正转向先进的计算工具。先搭建一个数据库，把所有高质量的论文收录进来；然后利用人工智能来进行检索筛查。<br>
2020年3月16日，美国白宫科学技术政策办公室建了一个COVID-19文献库，这个名为CORD-19的数据集被认为是迄今为止最大的。它拥有59,000多篇已发表的文章和预印本，包括可追溯至1950年代的冠状病毒研究。为了创建这个数据库，Google，Chan &amp; Zuckerberg Initiative和Allen AI研究所与美国国立卫生研究院及其他组织合作，使用包括自然语言处理在内的方法来识别和收集论文，并将PDF文件转换为机器学习算法可读的形式。以此希望CORD-19不仅可以帮助研究人员搜索相关文献，还可以从论文的发现中有意义的模式。但目前CORD-19馆藏中只有约40,000篇全文论文，且仅包含英语论文。这可能与不是所有出版商都公开了与COVID-19相关的论文有关。<br>
白宫已要求数据科学家开发工具来分析CORD-19数据集，以帮助研究人员回答由美国国家科学院和世界卫生组织确定的10个与流行病相关的高优先级研究问题。另外在Google Kaggle则列出了1500多个项目，Kaggle是Google Cloud旗下面向机器学习科学家的平台。<br>
数据挖掘工作的早期成果之一是“人工智能助力文献综述”。研究人员使用算法从CORD-19中收集了感兴趣的点，然后为每个点创建显示网页。但这个工作并不完全都是自动化的，因为算法并不能总是正确地提取相关的数据点。所以在新冠大流行病期间，“无所事事”的医学生和其他志愿者一直在对每个手稿的准确性进行筛查。<br>
另一个挑战是使这些机器学习工具更加用户友好。尽管数据科学家花费了20多年的时间来开发工具来挖掘科学文献中的主题，但微调方面可能不及人工准确，还有很多用户并没有意识到他们需要这些工具。<br>
当然让研究人员改变通常筛查文献的习惯，是很难的。<br>
以上就是Science这篇文章的大致内容。</p>
<p>然后我谈一下自己在应用text-ming做文献综述方面的一点经验。主要想说，为什么不把上面说到的两种办法（先筛查再机器学习）结合起来呢？目前的尝试主要体现在下面的文章里：<br>
Li, H., &amp; Van Ryzin, G. G. (2017). A Systematic Review of Experimental Studies in Public Management Journals. In O. James, S.Jilke, &amp; G. G. Van Ryzin (Eds.), Experiments in Public Management Research: Challenges &amp; Contributions (pp. 20–36). Cambridge University Press. https://doi.org/10.1017/9781316676912.003<br>
（参见：<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODY1NTEyMw==&amp;mid=2247483831&amp;idx=1&amp;sn=2c39b0fb65b013c0b544f28de83cd282&amp;chksm=eb52f84bdc25715d258320d3416e291b059fda89ed8c5b7bc83393716be3fc145a323d401105&amp;scene=21#wechat_redirect">公共管理如何搞实验？</a>）</p>
<p>Kim,M.H., Li, H., Holzer, M., &amp; Zhang, M. (2019a). Public Administration Research in Mainland China: A Systematic Review of Chinese Public Administration in English Language Journals (1996-2016).  International Journal of Public Administration, 49(2), 753–764.https://doi.org/10.1080/01900692.2018.1506936</p>
<p>Kim, M.-H., Li, H., Holzer, M., &amp; Zhang, M. (2019b). Public Administration Research in Mainland China. In A. Farazmand (Ed.), Global Encyclopedia of Public Administration, Public Policy, and Governance. Springer International Publishing. https://doi.org/10.1007/978-3-319-31816-5_3717-1<br>
（参见：<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODY1NTEyMw==&amp;mid=2247484066&amp;idx=1&amp;sn=2cf9c30a75e64285f64a19c37c6605f5&amp;chksm=eb52fb5edc257248b61c32761cbe7cb4a0e3a743fcf1347811f8313e2384744d4ed8c7fe0a60&amp;scene=21#wechat_redirect">过去20年，海外中国公管研究到底在研究什么呢？</a>）</p>
<p>我们的做法是先依靠一定的标准来缩减文献规模，然后再利用text-mining来助力综述。这样节省的是收集和建设初始文献数据库的时间和精力。另外就是降低机器的错误率。即便有整全数据库之后，算法识别困难或出错，可能也会造成困扰。<br>
我简单讲一下我们这样做的理由。先通过一定标准缩减文献规模后，一来可以减少数据库建设的工作量，二来可以使后续的算法更为准确。<br>
这里的关键问题是，学者对于什么是“整全”的文献综述，每个人理解不一样。即便用citespace或者自己编程来选文献，也面临对来源的取舍问题，例如要不要纳入书籍（及章节）还是不纳入等。这个时候必须要承认，不管是哪种限定文献选择范围的办法，事实上都不是整全的文献综述。<br>
有些人会结合几个文献来源，例如Google Scholar，Web of Science及Scopus等。从目前来看，Google收录的应该是最完整的。但有一些期刊没有电子化，就没有办法收录。所以从事实上来讲，整全也是很难的一件事情，尽管可以尝试通过众包方式完成，如果付费可能成本高昂；如果采用志愿者，可能耗时长久。<br>
那么整全所有文献再来综述是不是有必要？总体而言，文献综述的目的在于回顾过去的研究和展望未来可能的方向，也就是说，是展示一个“大致”而不是“精确”的图景。限定标准的文献综述相比整全文献综述，就好比抽样和Census的关系。<br>
关键在于“选择标准”。可惜的是，选择标准也没有统一意见。我们的做法是限定到Google Scholar的h5-index前20的公共政策与管理类的期刊。自然就会有人问为什么不以SSCI影响因子为准来选择期刊，或者其他的标准如Scientific Journal Rankings - SJR为准来选。<br>
都是测量影响，我“主观”认为h5-index的衡量比impact factor好一些，因为Google Scholar的涵盖范围要广一些，但h5-index同时又设定了过去5年里期刊共有h篇文章每篇被引用了h次以上，在广度和深度之间有一个平衡。</p>
<p>那么这样做会不会错过诺奖级贡献的文章呢？答案是有可能。</p>
<p>比如2018年的诺贝尔物理学奖获奖者Donna Strickland，她和老师Gérard Mourou一起获得诺奖文章发表在Optics Communications上面。这份刊物如果按照影响因子来算，是一份很一般的期刊。2018年的IF是1.887，怎么看都算低的。</p>
<p>又比如我提到过科斯1937的论文《企业的性质》（Coase, R. H. 1937. The nature of the firm. Economica, 4(16), 386-405. 这篇文章在Google Scholar的引用已经过了4万4千次。PA领域的朋友可能对这个数字没什么概念，这么说吧，你把James Perry和Ken Meier两人到目前为止发表的所有文章的引用数全部加起来，可能和科斯这一篇文章差不多。这篇文章和后来的《社会成本问题》一起为科斯带去了1991年的诺贝尔经济学奖）。但这篇文章发在完全不知名的杂志上。</p>
<p>最后小结一下：从实际操作而言，我们还是需要限定一个文献选择的范围，至于限定的标准则相对而言是非常主观的。如果限定标准适当，获诺奖的文章不一定纳入，但其诺奖级的贡献其实不会被忽略。</p>
<p>我们不妨扪心自问，就是如果目的是提供关于一个领域的大体图景，是不是就一定需要整全所有文献呢？或者说census不可得的情况下，相对而言具有代表性的期刊范围是不是足以让我们了解“大体图景”了呢？</p>
<p>我的看法是要平衡各种资源，时间、精力、容错率、操作难易程度等。简单粗暴一点来说：整全文献综述对大体图景而言，并不是必要的。</p>

              </div>
              <div class="toc-container">
                
              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://softuncle.github.io/post/wen-xian-ji-liang-zhuan-yong-gong-ju/">
              <h3 class="post-title">
                文献计量专用工具
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://softuncle.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
